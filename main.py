#!/usr/bin/env python3
"""
LLM Client para DeepSeek API
"""

import os
import json
from rich.console import Console
from rich.prompt import Prompt, Confirm
from rich.panel import Panel  # âœ… ImportaciÃ³n faltante
from config.settings import Config
from services.deepseek_service import DeepSeekService
from utils.helpers import print_message, loading_animation, format_conversation

console = Console()

class DeepSeekLLMClient:
    """Cliente interactivo para DeepSeek LLM"""
    
    def __init__(self):
        try:
            Config.validate_config()
            self.service = DeepSeekService()
            console.print("âœ… [green]ConfiguraciÃ³n validada correctamente[/green]")
        except Exception as e:
            console.print(f"âŒ [red]Error de configuraciÃ³n: {e}[/red]")
            exit(1)
    
    def single_query_mode(self):
        """Modo de consulta Ãºnica"""
        console.print("\nğŸ¯ [bold]Modo Consulta Ãšnica[/bold]")
        console.print("Escribe 'quit' para salir\n")
        
        while True:
            prompt = Prompt.ask("ğŸ‘¤ Tu pregunta")
            
            if prompt.lower() in ['quit', 'exit', 'salir']:
                break
            
            if not prompt.strip():
                continue
            
            try:
                with console.status("[bold green]Pensando...[/bold green]"):
                    response = self.service.generate_response(
                        prompt,
                        system_message="Eres un asistente Ãºtil y amable. Responde en el mismo idioma del usuario.",
                        temperature=0.7
                    )
                
                print_message("assistant", response)
                
            except Exception as e:
                console.print(f"âŒ [red]Error: {e}[/red]")
    
    def conversation_mode(self):
        """Modo conversaciÃ³n continua"""
        console.print("\nğŸ’¬ [bold]Modo ConversaciÃ³n[/bold]")
        console.print("Escribe 'quit' para salir o 'clear' para limpiar la conversaciÃ³n\n")
        
        conversation = []
        system_message = "Eres un asistente conversacional inteligente. MantÃ©n conversaciones naturales y Ãºtiles."
        
        conversation.append({"role": "system", "content": system_message})
        
        while True:
            user_input = Prompt.ask("ğŸ‘¤ TÃº")
            
            if user_input.lower() in ['quit', 'exit', 'salir']:
                break
            
            if user_input.lower() == 'clear':
                conversation = [conversation[0]]  # Mantener solo el system message
                console.print("ğŸ”„ ConversaciÃ³n limpiada")
                continue
            
            conversation.append({"role": "user", "content": user_input})
            
            try:
                with console.status("[bold green]Pensando...[/bold green]"):
                    response = self.service.multi_turn_conversation(
                        conversation,
                        temperature=0.7
                    )
                
                conversation.append({"role": "assistant", "content": response})
                print_message("assistant", response)
                
            except Exception as e:
                console.print(f"âŒ [red]Error: {e}[/red]")
                conversation.pop()  # Remove the failed user message
    
    def batch_processing_mode(self):
        """Procesamiento por lotes"""
        console.print("\nğŸ“¦ [bold]Modo Procesamiento por Lotes[/bold]")
        
        prompts = [
            "Explica la inteligencia artificial en 50 palabras",
            "Â¿CuÃ¡les son las ventajas de Python?",
            "Dame 3 consejos para aprender programaciÃ³n"
        ]
        
        for i, prompt in enumerate(prompts, 1):
            console.print(f"\nğŸ“ Procesando prompt {i}/3...")
            print_message("user", prompt)
            
            try:
                with console.status("[bold green]Procesando...[/bold green]"):
                    response = self.service.generate_response(prompt)
                
                print_message("assistant", response)
                
            except Exception as e:
                console.print(f"âŒ [red]Error en prompt {i}: {e}[/red]")
    
    def run(self):
        """Ejecuta la aplicaciÃ³n principal"""
        console.print(Panel.fit(
            "ğŸ¤– [bold blue]DeepSeek LLM Client[/bold blue]\n"
            "Interfaz para interactuar con modelos de lenguaje de DeepSeek",
            title="Bienvenido"
        ))
        
        while True:
            console.print("\nğŸ” [bold]Selecciona un modo:[/bold]")
            console.print("1. ğŸ¯ Consulta Ãºnica")
            console.print("2. ğŸ’¬ ConversaciÃ³n continua")
            console.print("3. ğŸ“¦ Procesamiento por lotes (ejemplo)")
            console.print("4. ğŸšª Salir")
            
            choice = Prompt.ask("Tu elecciÃ³n", choices=["1", "2", "3", "4"])
            
            if choice == "1":
                self.single_query_mode()
            elif choice == "2":
                self.conversation_mode()
            elif choice == "3":
                self.batch_processing_mode()
            elif choice == "4":
                console.print("ğŸ‘‹ Â¡Hasta pronto!")
                break

if __name__ == "__main__":
    client = DeepSeekLLMClient()
    client.run()